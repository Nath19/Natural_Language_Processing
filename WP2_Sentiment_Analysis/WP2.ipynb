{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tagging is the process of converting a sentence, in the form of a list of words, into a list of tuples, where each tuple is of the form (word, tag). The tag is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on.\n",
    "\n",
    "The main goal of this notebook is to identify if reviews of movies are positives or negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the taggers are trainable. They use a list of tagged sentences as their training data. With these training sentences, the tagger generates an internal model that will tell it how to tag a word. Other taggers use external data sources or match word patterns to choose a tag for a word.\n",
    "\n",
    "Here we will use UnigramTagger by giving it a list of tagged sentences at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/nathanamar/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()\n",
    "tagger = UnigramTagger(train_sents)\n",
    "treebank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the first sentence as a list of words, and can see how it is transformed by the tag() function into a list of tagged tokens.\n",
    "\n",
    "To identify positivity or negativity of the reviews we will use SentiWordNet, a lexical resource for opinion mining. SentiWordNet assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/nathanamar/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('good', 'a'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('good', 'a'))[0].neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('good', 'a'))[0].obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to process the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that helps us replace words matching regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do not hesistate to ask questions'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "replacement_patterns = [\n",
    "    (r'â€™', '\\''),\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'cannot'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would'),\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns): \n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s) \n",
    "        return s\n",
    "    \n",
    "\n",
    "replacer=RegexpReplacer()\n",
    "replacer.replace(\"Don't hesistate to ask questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_file = open('/Users/nathanamar/Desktop/ESILV/A5/Advanced Machine Learning for Big Data Text Processing/WP2/data/review_polarity/txt_sentoken/pos/cv000_29590.txt', 'r', encoding='utf-8')\n",
    "file_to_string = open_file.read()\n",
    "type(file_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success , whether they're about superheroes ( batm\n",
      "success , whether they are about superheroes ( bat\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "text_replaced = replacer.replace(file_to_string)\n",
    "print(file_to_string[50:100])\n",
    "print(text_replaced[50:100])\n",
    "print(type(text_replaced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing the words by regular expressions, we will tokenize the reviews in a list of sentences, and then in a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'films adapted from comic books have had plenty of success , whether they are about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there is never really been a comic book like from hell before .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sentences = tokenizer.tokenize(text_replaced)\n",
    "len(sentences)#27\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen .\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films',\n",
       " 'adapted',\n",
       " 'from',\n",
       " 'comic',\n",
       " 'books',\n",
       " 'have',\n",
       " 'had',\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'success',\n",
       " 'whether',\n",
       " 'they',\n",
       " 'are',\n",
       " 'about',\n",
       " 'superheroes',\n",
       " 'batman',\n",
       " 'superman',\n",
       " 'spawn',\n",
       " 'or',\n",
       " 'geared',\n",
       " 'toward',\n",
       " 'kids',\n",
       " 'casper',\n",
       " 'or',\n",
       " 'the',\n",
       " 'arthouse',\n",
       " 'crowd',\n",
       " 'ghost',\n",
       " 'world',\n",
       " 'but',\n",
       " 'there',\n",
       " 'is',\n",
       " 'never',\n",
       " 'really',\n",
       " 'been',\n",
       " 'a',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'like',\n",
       " 'from',\n",
       " 'hell',\n",
       " 'before']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = tokenizer.tokenize(sentences[i])\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the tagger trained earlier using the UnigramTagger to tag each word of all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('films', 'NNS'),\n",
       " ('adapted', 'VBD'),\n",
       " ('from', 'IN'),\n",
       " ('comic', None),\n",
       " ('books', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('had', 'VBD'),\n",
       " ('plenty', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('success', 'NN'),\n",
       " ('whether', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('about', 'IN'),\n",
       " ('superheroes', None),\n",
       " ('batman', None),\n",
       " ('superman', None),\n",
       " ('spawn', None),\n",
       " ('or', 'CC'),\n",
       " ('geared', None),\n",
       " ('toward', 'IN'),\n",
       " ('kids', 'NNS'),\n",
       " ('casper', None),\n",
       " ('or', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('arthouse', None),\n",
       " ('crowd', 'NN'),\n",
       " ('ghost', None),\n",
       " ('world', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('there', 'EX'),\n",
       " ('is', 'VBZ'),\n",
       " ('never', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('comic', None),\n",
       " ('book', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('from', 'IN'),\n",
       " ('hell', None),\n",
       " ('before', 'IN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent =[]\n",
    "for sentence in sentences:\n",
    "    tagged_sent.append(tagger.tag(sentence))\n",
    "tagged_sent[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags used by *SentiWordNet* are different than the tags of the UnigramTagger. For example, an adjectif is tagged as **_'JJ'_**  in our tagger and it is tagged as **_'a'_** in *SentiWordNet*.\n",
    "\n",
    "The function below allows us to get the 3 scores (positive, negative, objective) of a word by using a tuple *(word, tag)* as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('kill', 'v'))[0].neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('beautiful', 'a'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('good', 'a'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('never', 'r'))[0].neg_score() #R MEANS adverb = RB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0]\n",
      "[0.125, 0.0, 0.875]\n",
      "[0.0, 0.625, 0.375]\n",
      "[0.0, 0.0, 1.0]\n",
      "[0.75, 0.0, 0.25]\n",
      "[0.25, 0.125, 0.625]\n"
     ]
    }
   ],
   "source": [
    "def word_scores(wordntag):\n",
    "    result = []\n",
    "    word, tag = wordntag\n",
    "    if(tag == 'JJ'):\n",
    "        if( len(list(swn.senti_synsets(word, 'a'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'a'))[0].pos_score(), list(swn.senti_synsets(word, 'a'))[0].neg_score(), list(swn.senti_synsets(word, 'a'))[0].obj_score()])\n",
    "        else:\n",
    "            result = [0.0, 0.0, 0.0]\n",
    "    elif (tag == 'NNS' or tag == 'NN'):\n",
    "        if( len(list(swn.senti_synsets(word, 'n'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'n'))[0].pos_score(), list(swn.senti_synsets(word, 'n'))[0].neg_score(), list(swn.senti_synsets(word, 'n'))[0].obj_score()])\n",
    "        else:\n",
    "            result = [0.0, 0.0, 0.0]\n",
    "    elif(tag == 'RB'):\n",
    "        if( len(list(swn.senti_synsets(word, 'r'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'r'))[0].pos_score(), list(swn.senti_synsets(word, 'r'))[0].neg_score(), list(swn.senti_synsets(word, 'r'))[0].obj_score()])\n",
    "        else:\n",
    "            result = [0.0, 0.0, 0.0]\n",
    "    elif(tag == 'VBD' or tag == 'VBP' or tag == 'VBN' or tag == 'VBZ'):\n",
    "        if( len(list(swn.senti_synsets(word, 'v'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'v'))[0].pos_score(), list(swn.senti_synsets(word, 'v'))[0].neg_score(), list(swn.senti_synsets(word, 'v'))[0].obj_score()])\n",
    "    else:\n",
    "        result = [0.0, 0.0, 0.0]\n",
    "    return result;\n",
    "\n",
    "print(word_scores(tagged_sent[0][0]))\n",
    "print(word_scores(tagged_sent[0][9]))#Sucess\n",
    "print(word_scores(tagged_sent[0][32])) # with the word never\n",
    "print(word_scores(tagged_sent[6][39]))#objectif 1 for crime\n",
    "print(word_scores(tagged_sent[14][3])) # 0.\n",
    "print(word_scores(tagged_sent[0][12]))# 0.25 positif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('good', 'JJ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent[14][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('are', 'VBP')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent[0][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST WITH THE VBP ARE\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('are', 'v'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('success', 'NN')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('adapted', 'VBD')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('adapted', 'v'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply that function for every word of each sentence to get a list of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('films', 'NNS'),\n",
       "  ('adapted', 'VBD'),\n",
       "  ('from', 'IN'),\n",
       "  ('comic', None),\n",
       "  ('books', 'NNS'),\n",
       "  ('have', 'VBP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('plenty', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('success', 'NN'),\n",
       "  ('whether', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('about', 'IN'),\n",
       "  ('superheroes', None),\n",
       "  ('batman', None),\n",
       "  ('superman', None),\n",
       "  ('spawn', None),\n",
       "  ('or', 'CC'),\n",
       "  ('geared', None),\n",
       "  ('toward', 'IN'),\n",
       "  ('kids', 'NNS'),\n",
       "  ('casper', None),\n",
       "  ('or', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('arthouse', None),\n",
       "  ('crowd', 'NN'),\n",
       "  ('ghost', None),\n",
       "  ('world', 'NN'),\n",
       "  ('but', 'CC'),\n",
       "  ('there', 'EX'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('never', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('been', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('comic', None),\n",
       "  ('book', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('from', 'IN'),\n",
       "  ('hell', None),\n",
       "  ('before', 'IN')],\n",
       " [('for', 'IN'),\n",
       "  ('starters', 'NNS'),\n",
       "  ('it', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('created', 'VBN'),\n",
       "  ('by', 'IN'),\n",
       "  ('alan', None),\n",
       "  ('moore', None),\n",
       "  ('and', 'CC'),\n",
       "  ('eddie', None),\n",
       "  ('campbell', None),\n",
       "  ('who', 'WP'),\n",
       "  ('brought', 'VBN'),\n",
       "  ('the', 'DT'),\n",
       "  ('medium', None),\n",
       "  ('to', 'TO'),\n",
       "  ('a', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('new', 'JJ'),\n",
       "  ('level', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('mid', None),\n",
       "  ('80s', None),\n",
       "  ('with', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('12', 'CD'),\n",
       "  ('part', 'NN'),\n",
       "  ('series', 'NN'),\n",
       "  ('called', 'VBN'),\n",
       "  ('the', 'DT'),\n",
       "  ('watchmen', None)],\n",
       " [('to', 'TO'),\n",
       "  ('say', 'VBP'),\n",
       "  ('moore', None),\n",
       "  ('and', 'CC'),\n",
       "  ('campbell', None),\n",
       "  ('thoroughly', None),\n",
       "  ('researched', None),\n",
       "  ('the', 'DT'),\n",
       "  ('subject', 'JJ'),\n",
       "  ('of', 'IN'),\n",
       "  ('jack', None),\n",
       "  ('the', 'DT'),\n",
       "  ('ripper', None),\n",
       "  ('would', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('like', 'IN'),\n",
       "  ('saying', 'VBG'),\n",
       "  ('michael', None),\n",
       "  ('jackson', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('starting', 'VBG'),\n",
       "  ('to', 'TO'),\n",
       "  ('look', 'NN'),\n",
       "  ('a', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('odd', 'JJ')],\n",
       " [('the', 'DT'),\n",
       "  ('book', 'NN'),\n",
       "  ('or', 'CC'),\n",
       "  ('graphic', None),\n",
       "  ('novel', 'NN'),\n",
       "  ('if', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('over', 'IN'),\n",
       "  ('500', 'CD'),\n",
       "  ('pages', 'NNS'),\n",
       "  ('long', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('includes', 'VBZ'),\n",
       "  ('nearly', 'RB'),\n",
       "  ('30', 'CD'),\n",
       "  ('more', 'JJR'),\n",
       "  ('that', 'IN'),\n",
       "  ('consist', 'VBP'),\n",
       "  ('of', 'IN'),\n",
       "  ('nothing', 'NN'),\n",
       "  ('but', 'CC'),\n",
       "  ('footnotes', None)],\n",
       " [('in', 'IN'),\n",
       "  ('other', 'JJ'),\n",
       "  ('words', 'NNS'),\n",
       "  ('do', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('dismiss', 'VBP'),\n",
       "  ('this', 'DT'),\n",
       "  ('film', 'NN'),\n",
       "  ('because', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('its', 'PRP$'),\n",
       "  ('source', 'NN')],\n",
       " [('if', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('get', 'VB'),\n",
       "  ('past', 'JJ'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('comic', None),\n",
       "  ('book', 'NN'),\n",
       "  ('thing', 'NN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('might', 'MD'),\n",
       "  ('find', 'VB'),\n",
       "  ('another', 'DT'),\n",
       "  ('stumbling', None),\n",
       "  ('block', 'VB'),\n",
       "  ('in', 'IN'),\n",
       "  ('from', 'IN'),\n",
       "  ('hell', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('directors', 'NNS'),\n",
       "  ('albert', None),\n",
       "  ('and', 'CC'),\n",
       "  ('allen', None),\n",
       "  ('hughes', None)],\n",
       " [('getting', 'VBG'),\n",
       "  ('the', 'DT'),\n",
       "  ('hughes', None),\n",
       "  ('brothers', None),\n",
       "  ('to', 'TO'),\n",
       "  ('direct', 'JJ'),\n",
       "  ('this', 'DT'),\n",
       "  ('seems', 'VBZ'),\n",
       "  ('almost', 'RB'),\n",
       "  ('as', 'IN'),\n",
       "  ('ludicrous', None),\n",
       "  ('as', 'IN'),\n",
       "  ('casting', 'VBG'),\n",
       "  ('carrot', None),\n",
       "  ('top', 'JJ'),\n",
       "  ('in', 'IN'),\n",
       "  ('well', 'RB'),\n",
       "  ('anything', 'NN'),\n",
       "  ('but', 'CC'),\n",
       "  ('riddle', None),\n",
       "  ('me', 'PRP'),\n",
       "  ('this', 'DT'),\n",
       "  ('who', 'WP'),\n",
       "  ('better', 'JJR'),\n",
       "  ('to', 'TO'),\n",
       "  ('direct', 'JJ'),\n",
       "  ('a', 'DT'),\n",
       "  ('film', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('set', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('ghetto', None),\n",
       "  ('and', 'CC'),\n",
       "  ('features', 'NNS'),\n",
       "  ('really', 'RB'),\n",
       "  ('violent', None),\n",
       "  ('street', 'NN'),\n",
       "  ('crime', 'NN'),\n",
       "  ('than', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('mad', None),\n",
       "  ('geniuses', None),\n",
       "  ('behind', 'IN'),\n",
       "  ('menace', None),\n",
       "  ('ii', None),\n",
       "  ('society', 'NN')],\n",
       " [('the', 'DT'),\n",
       "  ('ghetto', None),\n",
       "  ('in', 'IN'),\n",
       "  ('question', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('of', 'IN'),\n",
       "  ('course', 'NN'),\n",
       "  ('whitechapel', None),\n",
       "  ('in', 'IN'),\n",
       "  ('1888', None),\n",
       "  ('london', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('east', None),\n",
       "  ('end', 'NN')],\n",
       " [('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('filthy', None),\n",
       "  ('sooty', None),\n",
       "  ('place', 'NN'),\n",
       "  ('where', 'WRB'),\n",
       "  ('the', 'DT'),\n",
       "  ('whores', None),\n",
       "  ('called', 'VBN'),\n",
       "  ('unfortunates', None),\n",
       "  ('are', 'VBP'),\n",
       "  ('starting', 'VBG'),\n",
       "  ('to', 'TO'),\n",
       "  ('get', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('nervous', 'JJ'),\n",
       "  ('about', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('mysterious', None),\n",
       "  ('psychopath', None),\n",
       "  ('who', 'WP'),\n",
       "  ('has', 'VBZ'),\n",
       "  ('been', 'VBN'),\n",
       "  ('carving', None),\n",
       "  ('through', 'IN'),\n",
       "  ('their', 'PRP$'),\n",
       "  ('profession', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('surgical', None),\n",
       "  ('precision', None)],\n",
       " [('when', 'WRB'),\n",
       "  ('the', 'DT'),\n",
       "  ('first', 'JJ'),\n",
       "  ('stiff', 'JJ'),\n",
       "  ('turns', 'VBZ'),\n",
       "  ('up', 'RP'),\n",
       "  ('copper', 'NN'),\n",
       "  ('peter', None),\n",
       "  ('godley', None),\n",
       "  ('robbie', None),\n",
       "  ('coltrane', None),\n",
       "  ('the', 'DT'),\n",
       "  ('world', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('not', 'RB'),\n",
       "  ('enough', 'RB'),\n",
       "  ('calls', 'VBZ'),\n",
       "  ('in', 'IN'),\n",
       "  ('inspector', None),\n",
       "  ('frederick', None),\n",
       "  ('abberline', None),\n",
       "  ('johnny', None),\n",
       "  ('depp', None),\n",
       "  ('blow', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('crack', 'NN'),\n",
       "  ('the', 'DT'),\n",
       "  ('case', 'NN')],\n",
       " [('abberline', None),\n",
       "  ('a', 'DT'),\n",
       "  ('widower', None),\n",
       "  ('has', 'VBZ'),\n",
       "  ('prophetic', None),\n",
       "  ('dreams', None),\n",
       "  ('he', 'PRP'),\n",
       "  ('unsuccessfully', 'RB'),\n",
       "  ('tries', None),\n",
       "  ('to', 'TO'),\n",
       "  ('quell', None),\n",
       "  ('with', 'IN'),\n",
       "  ('copious', None),\n",
       "  ('amounts', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('absinthe', None),\n",
       "  ('and', 'CC'),\n",
       "  ('opium', None)],\n",
       " [('upon', 'IN'),\n",
       "  ('arriving', None),\n",
       "  ('in', 'IN'),\n",
       "  ('whitechapel', None),\n",
       "  ('he', 'PRP'),\n",
       "  ('befriends', None),\n",
       "  ('an', 'DT'),\n",
       "  ('unfortunate', None),\n",
       "  ('named', 'VBN'),\n",
       "  ('mary', None),\n",
       "  ('kelly', None),\n",
       "  ('heather', None),\n",
       "  ('graham', None),\n",
       "  ('say', 'VBP'),\n",
       "  ('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('not', 'RB'),\n",
       "  ('so', 'RB'),\n",
       "  ('and', 'CC'),\n",
       "  ('proceeds', 'NNS'),\n",
       "  ('to', 'TO'),\n",
       "  ('investigate', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('horribly', None),\n",
       "  ('gruesome', None),\n",
       "  ('crimes', None),\n",
       "  ('that', 'IN'),\n",
       "  ('even', 'RB'),\n",
       "  ('the', 'DT'),\n",
       "  ('police', 'NNS'),\n",
       "  ('surgeon', 'NN'),\n",
       "  ('cannot', None),\n",
       "  ('stomach', None)],\n",
       " [('i', None),\n",
       "  ('do', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('think', 'VBP'),\n",
       "  ('anyone', 'NN'),\n",
       "  ('needs', 'VBZ'),\n",
       "  ('to', 'TO'),\n",
       "  ('be', 'VB'),\n",
       "  ('briefed', None),\n",
       "  ('on', 'IN'),\n",
       "  ('jack', None),\n",
       "  ('the', 'DT'),\n",
       "  ('ripper', None),\n",
       "  ('so', 'RB'),\n",
       "  ('i', None),\n",
       "  ('will', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('go', 'VB'),\n",
       "  ('into', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('particulars', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('other', 'JJ'),\n",
       "  ('than', 'IN'),\n",
       "  ('to', 'TO'),\n",
       "  ('say', 'VBP'),\n",
       "  ('moore', None),\n",
       "  ('and', 'CC'),\n",
       "  ('campbell', None),\n",
       "  ('have', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('unique', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('interesting', 'JJ'),\n",
       "  ('theory', 'NN'),\n",
       "  ('about', 'IN'),\n",
       "  ('both', 'DT'),\n",
       "  ('the', 'DT'),\n",
       "  ('identity', None),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('killer', None),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('reasons', 'NNS'),\n",
       "  ('he', 'PRP'),\n",
       "  ('chooses', 'VBZ'),\n",
       "  ('to', 'TO'),\n",
       "  ('slay', None)],\n",
       " [('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('comic', None),\n",
       "  ('they', 'PRP'),\n",
       "  ('do', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('bother', None),\n",
       "  ('cloaking', None),\n",
       "  ('the', 'DT'),\n",
       "  ('identity', None),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('ripper', None),\n",
       "  ('but', 'CC'),\n",
       "  ('screenwriters', 'NNS'),\n",
       "  ('terry', None),\n",
       "  ('hayes', None),\n",
       "  ('vertical', None),\n",
       "  ('limit', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('rafael', None),\n",
       "  ('yglesias', None),\n",
       "  ('les', None),\n",
       "  ('mis', None)],\n",
       " [('rables', None),\n",
       "  ('do', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('good', 'JJ'),\n",
       "  ('job', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('keeping', 'VBG'),\n",
       "  ('him', 'PRP'),\n",
       "  ('hidden', 'VBN'),\n",
       "  ('from', 'IN'),\n",
       "  ('viewers', 'NNS'),\n",
       "  ('until', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('very', 'RB'),\n",
       "  ('end', 'NN')],\n",
       " [('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('funny', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('watch', 'NN'),\n",
       "  ('the', 'DT'),\n",
       "  ('locals', None),\n",
       "  ('blindly', None),\n",
       "  ('point', 'NN'),\n",
       "  ('the', 'DT'),\n",
       "  ('finger', None),\n",
       "  ('of', 'IN'),\n",
       "  ('blame', None),\n",
       "  ('at', 'IN'),\n",
       "  ('jews', None),\n",
       "  ('and', 'CC'),\n",
       "  ('indians', None),\n",
       "  ('because', 'IN'),\n",
       "  ('after', 'IN'),\n",
       "  ('all', 'DT'),\n",
       "  ('an', 'DT'),\n",
       "  ('englishman', None),\n",
       "  ('could', 'MD'),\n",
       "  ('never', 'RB'),\n",
       "  ('be', 'VB'),\n",
       "  ('capable', None),\n",
       "  ('of', 'IN'),\n",
       "  ('committing', 'VBG'),\n",
       "  ('such', 'JJ'),\n",
       "  ('ghastly', None),\n",
       "  ('acts', 'VBZ')],\n",
       " [('and', 'CC'),\n",
       "  ('from', 'IN'),\n",
       "  ('hell', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('ending', 'VBG'),\n",
       "  ('had', 'VBD'),\n",
       "  ('me', 'PRP'),\n",
       "  ('whistling', None),\n",
       "  ('the', 'DT'),\n",
       "  ('stonecutters', None),\n",
       "  ('song', None),\n",
       "  ('from', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('simpsons', None),\n",
       "  ('for', 'IN'),\n",
       "  ('days', 'NNS'),\n",
       "  ('who', 'WP'),\n",
       "  ('holds', 'VBZ'),\n",
       "  ('back', 'RB'),\n",
       "  ('the', 'DT'),\n",
       "  ('electric', 'JJ'),\n",
       "  ('car', 'NN'),\n",
       "  ('who', 'WP'),\n",
       "  ('made', 'VBN'),\n",
       "  ('steve', None),\n",
       "  ('guttenberg', None),\n",
       "  ('a', 'DT'),\n",
       "  ('star', 'NN')],\n",
       " [],\n",
       " [('do', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('worry', 'VBP'),\n",
       "  ('it', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('all', 'DT'),\n",
       "  ('make', 'VB'),\n",
       "  ('sense', 'NN'),\n",
       "  ('when', 'WRB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('see', 'VB'),\n",
       "  ('it', 'PRP')],\n",
       " [('now', 'RB'),\n",
       "  ('onto', 'IN'),\n",
       "  ('from', 'IN'),\n",
       "  ('hell', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('appearance', None),\n",
       "  ('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('certainly', 'RB'),\n",
       "  ('dark', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('bleak', None),\n",
       "  ('enough', 'RB'),\n",
       "  ('and', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('surprising', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('see', 'VB'),\n",
       "  ('how', 'WRB'),\n",
       "  ('much', 'RB'),\n",
       "  ('more', 'JJR'),\n",
       "  ('it', 'PRP'),\n",
       "  ('looks', 'VBZ'),\n",
       "  ('like', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('tim', None),\n",
       "  ('burton', None),\n",
       "  ('film', 'NN'),\n",
       "  ('than', 'IN'),\n",
       "  ('planet', None),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('apes', None),\n",
       "  ('did', 'VBD'),\n",
       "  ('at', 'IN'),\n",
       "  ('times', 'NNS'),\n",
       "  ('it', 'PRP'),\n",
       "  ('seems', 'VBZ'),\n",
       "  ('like', 'IN'),\n",
       "  ('sleepy', None),\n",
       "  ('hollow', None),\n",
       "  ('2', 'CD')],\n",
       " [('the', 'DT'),\n",
       "  ('print', 'VB'),\n",
       "  ('i', None),\n",
       "  ('saw', 'VBD'),\n",
       "  ('was', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('completely', 'RB'),\n",
       "  ('finished', 'VBD'),\n",
       "  ('both', 'DT'),\n",
       "  ('color', 'VB'),\n",
       "  ('and', 'CC'),\n",
       "  ('music', 'NN'),\n",
       "  ('had', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('been', 'VBN'),\n",
       "  ('finalized', 'VBN'),\n",
       "  ('so', 'RB'),\n",
       "  ('no', 'DT'),\n",
       "  ('comments', 'NNS'),\n",
       "  ('about', 'IN'),\n",
       "  ('marilyn', None),\n",
       "  ('manson', None),\n",
       "  ('but', 'CC'),\n",
       "  ('cinematographer', None),\n",
       "  ('peter', None),\n",
       "  ('deming', None),\n",
       "  ('do', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('say', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('word', 'NN'),\n",
       "  ('ably', None),\n",
       "  ('captures', None),\n",
       "  ('the', 'DT'),\n",
       "  ('dreariness', None),\n",
       "  ('of', 'IN'),\n",
       "  ('victorian', None),\n",
       "  ('era', 'NN'),\n",
       "  ('london', None),\n",
       "  ('and', 'CC'),\n",
       "  ('helped', 'VBD'),\n",
       "  ('make', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('flashy', 'JJ'),\n",
       "  ('killing', 'VBG'),\n",
       "  ('scenes', 'NNS'),\n",
       "  ('remind', None),\n",
       "  ('me', 'PRP'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('crazy', None),\n",
       "  ('flashbacks', None),\n",
       "  ('in', 'IN'),\n",
       "  ('twin', 'NN'),\n",
       "  ('peaks', 'NNS'),\n",
       "  ('even', 'RB'),\n",
       "  ('though', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('violence', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('film', 'NN'),\n",
       "  ('pales', None),\n",
       "  ('in', 'IN'),\n",
       "  ('comparison', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('that', 'IN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('black', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('white', 'JJ'),\n",
       "  ('comic', None)],\n",
       " [('oscar', None),\n",
       "  ('winner', 'NN'),\n",
       "  ('martin', None),\n",
       "  ('childs', None),\n",
       "  ('shakespeare', None),\n",
       "  ('in', 'IN'),\n",
       "  ('love', None),\n",
       "  ('production', 'NN'),\n",
       "  ('design', 'NN'),\n",
       "  ('turns', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('original', 'JJ'),\n",
       "  ('prague', None),\n",
       "  ('surroundings', None),\n",
       "  ('into', 'IN'),\n",
       "  ('one', 'CD'),\n",
       "  ('creepy', None),\n",
       "  ('place', 'NN')],\n",
       " [('even', 'RB'),\n",
       "  ('the', 'DT'),\n",
       "  ('acting', 'JJ'),\n",
       "  ('in', 'IN'),\n",
       "  ('from', 'IN'),\n",
       "  ('hell', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('solid', 'JJ'),\n",
       "  ('with', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('dreamy', None),\n",
       "  ('depp', None),\n",
       "  ('turning', 'VBG'),\n",
       "  ('in', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('typically', 'RB'),\n",
       "  ('strong', 'JJ'),\n",
       "  ('performance', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('deftly', None),\n",
       "  ('handling', 'NN'),\n",
       "  ('a', 'DT'),\n",
       "  ('british', None),\n",
       "  ('accent', None)],\n",
       " [('ians', None),\n",
       "  ('holm', None),\n",
       "  ('joe', None),\n",
       "  ('gould', None),\n",
       "  ('is', 'VBZ'),\n",
       "  ('secret', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('richardson', None),\n",
       "  ('102', 'CD'),\n",
       "  ('dalmatians', None),\n",
       "  ('log', 'VB'),\n",
       "  ('in', 'IN'),\n",
       "  ('great', 'JJ'),\n",
       "  ('supporting', None),\n",
       "  ('roles', None),\n",
       "  ('but', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('big', 'JJ'),\n",
       "  ('surprise', 'NN'),\n",
       "  ('here', 'RB'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('graham', None)],\n",
       " [('i', None),\n",
       "  ('cringed', None),\n",
       "  ('the', 'DT'),\n",
       "  ('first', 'JJ'),\n",
       "  ('time', 'NN'),\n",
       "  ('she', 'PRP'),\n",
       "  ('opened', 'VBD'),\n",
       "  ('her', 'PRP$'),\n",
       "  ('mouth', None),\n",
       "  ('imagining', None),\n",
       "  ('her', 'PRP$'),\n",
       "  ('attempt', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('an', 'DT'),\n",
       "  ('irish', None),\n",
       "  ('accent', None),\n",
       "  ('but', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('actually', 'RB'),\n",
       "  ('was', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('half', 'DT'),\n",
       "  ('bad', 'JJ')],\n",
       " [('the', 'DT'),\n",
       "  ('film', 'NN'),\n",
       "  ('however', 'RB'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('all', 'DT'),\n",
       "  ('good', 'JJ')],\n",
       " [('2', 'CD'),\n",
       "  ('00', None),\n",
       "  ('r', None),\n",
       "  ('for', 'IN'),\n",
       "  ('strong', 'JJ'),\n",
       "  ('violence', 'NN'),\n",
       "  ('gore', None),\n",
       "  ('sexuality', None),\n",
       "  ('language', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('drug', 'NN'),\n",
       "  ('content', 'NN')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 1.0], [0.25, 0.0, 0.75], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.25, 0.0, 0.75], [0.25, 0.0, 0.75], [0.0, 0.375, 0.625], [0.0, 0.0, 0.0], [0.125, 0.0, 0.875], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.25, 0.125, 0.625], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.25, 0.125, 0.625], [0.0, 0.625, 0.375], [0.625, 0.0, 0.375], [0.25, 0.125, 0.625], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for sentence in tagged_sent:\n",
    "    list_scores = []\n",
    "    for word in sentence:\n",
    "        list_scores.append(word_scores(word))\n",
    "    scores.append(list_scores)\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "The question is now to determine how will we decide if a review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First approach : we decide based on majority**\n",
    "\n",
    "If the positive score is bigger than the negative one, then it is a positive review. Else it's a negative one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first sum the positive and negative scores for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05357142857142857, 0.03273809523809524, 0.29464285714285715]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_score = []\n",
    "for list_score in scores:\n",
    "    pos, neg, obj = 0.0, 0.0, 0.0\n",
    "    for score in list_score:\n",
    "        pos += score[0]\n",
    "        neg += score[1]\n",
    "        obj += score[2]\n",
    "    if(len(list_score) != 0):\n",
    "        sum_score.append([pos/len(list_score), neg/len(list_score), obj/len(list_score)])\n",
    "    else:\n",
    "        sum_score.append([0.0, 0.0, 0.0])\n",
    "sum_score[0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sum the scores of all sentences to get the global score of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0361269223282653, 0.03247102490788594, 0.2605192039899847]\n"
     ]
    }
   ],
   "source": [
    "pos, neg, obj = 0.0, 0.0, 0.0\n",
    "for score in sum_score:\n",
    "    pos += score[0]\n",
    "    neg += score[1]\n",
    "    obj += score[2]\n",
    "pos /= len(sum_score)\n",
    "neg /= len(sum_score)\n",
    "obj /= len(sum_score)\n",
    "print([pos, neg, obj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that does the whole process for a text put in argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0361269223282653, 0.03247102490788594, 0.2605192039899847]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sumScores(file):\n",
    "    open_file = open(file, 'r', encoding='utf-8')\n",
    "    file_to_string = open_file.read()\n",
    "    \n",
    "    text_replaced = replacer.replace(file_to_string)\n",
    "    \n",
    "    tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(text_replaced)\n",
    "    \n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = tokenizer.tokenize(sentences[i])\n",
    "        \n",
    "    tagged_sent = []\n",
    "    for sentence in sentences:\n",
    "        tagged_sent.append(tagger.tag(sentence))\n",
    "        \n",
    "    scores = []\n",
    "    for sentence in tagged_sent:\n",
    "        list_scores = []\n",
    "        for word in sentence:\n",
    "            list_scores.append(word_scores(word))\n",
    "        scores.append(list_scores)\n",
    "        \n",
    "    sum_score = []\n",
    "    for list_score in scores:\n",
    "        pos, neg, obj = 0.0, 0.0, 0.0\n",
    "        for score in list_score:\n",
    "            pos += score[0]\n",
    "            neg += score[1]\n",
    "            obj += score[2]\n",
    "        if(len(list_score) != 0):\n",
    "            sum_score.append([pos/len(list_score), neg/len(list_score), obj/len(list_score)])\n",
    "        else:\n",
    "            sum_score.append([0.0, 0.0, 0.0])\n",
    "        \n",
    "    pos, neg, obj = 0.0, 0.0, 0.0\n",
    "    for score in sum_score:\n",
    "        pos += score[0]\n",
    "        neg += score[1]\n",
    "        obj += score[2]\n",
    "    if(len(sum_score) != 0):\n",
    "        pos /= len(sum_score)\n",
    "        neg /= len(sum_score)\n",
    "        obj /= len(sum_score)\n",
    "    return([pos, neg, obj])\n",
    "    \n",
    "sumScores('data/review_polarity/txt_sentoken/pos/cv000_29590.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that scoring technique on all positive reviews and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__First decision :__ We choose the highest value (between neg and pos) to determine if a review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pos_reviews = os.listdir('data/review_polarity/txt_sentoken/pos')\n",
    "neg_reviews = os.listdir('data/review_polarity/txt_sentoken/pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846 154\n"
     ]
    }
   ],
   "source": [
    "pos, neg = 0, 0\n",
    "for review in pos_reviews:\n",
    "    if(review[0] != 'c'):\n",
    "        continue\n",
    "    score = sumScores('data/review_polarity/txt_sentoken/pos/'+review)\n",
    "    if(score[0] > score[1]):\n",
    "        pos += 1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(pos, neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
